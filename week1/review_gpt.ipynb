{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83f7c50f-8a56-473a-b70b-08b274a10b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('text.txt','r',encoding = 'utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b3873ce-ecf8-4107-818a-08de0cbacf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddbea82f-9b74-4765-9f31-022bed399609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch : i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s : [stoi[c] for c in s]\n",
    "decode = lambda l : ''.join([itos[i] for i in l])\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "665a67d2-9eb6-4df1-be90-9c8a1c656b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text),dtype = torch.long)\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3c1ed4-8a44-4b47-a420-67f2c2f536a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f2d165f-e27a-4668-b6c2-5973b92cc8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfaf075b-fd06-42bc-960a-a5490aacd4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data)-block_size,(batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb,yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee7f81bf-54d9-4d74-9f92-79ac6c7e60ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MufR3!yC NHKGY?C3eDEGMp-VCcZN3aoRN&powfXmB.EOX.aFl3sitGj&WcGpoEfRvHLbR?\n",
      "JxHofRX,MccAWBTF.ALF$mQ;!GY:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "\n",
    "        return logits,loss\n",
    "\n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits,dim = -1)\n",
    "            idx_next = torch.multinomial(probs,num_samples = 1)\n",
    "            idx = torch.cat((idx,idx_next),dim = 1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel (vocab_size)\n",
    "logits, loss = m(xb,yb)\n",
    "\n",
    "idx1 = torch.zeros((1,1),dtype = torch.long)\n",
    "print(decode(m.generate(idx1,max_new_tokens = 100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ec4550e-841e-421e-9d7b-92255fb144c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m optimizer = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdamW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\adamw.py:37\u001b[39m, in \u001b[36mAdamW.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize, foreach, capturable, differentiable, fused)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     24\u001b[39m     params: ParamsT,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     fused: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     36\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\adam.py:101\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m defaults = {\n\u001b[32m     89\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: lr,\n\u001b[32m     90\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m: betas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdecoupled_weight_decay\u001b[39m\u001b[33m\"\u001b[39m: decoupled_weight_decay,\n\u001b[32m    100\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\optimizer.py:401\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    398\u001b[39m     param_groups = [{\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: param_groups}]\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[38;5;28mself\u001b[39m._warned_capturable_if_run_uncaptured = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_compile.py:46\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m disable_fn = \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[33m\"\u001b[39m\u001b[33m__dynamo_disable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# We can safely turn off functools.wraps here because the inner\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# already wraps fn in the outer scope.\u001b[39;00m\n\u001b[32m     50\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     aot_compile,\n\u001b[32m     15\u001b[39m     config,\n\u001b[32m     16\u001b[39m     convert_frame,\n\u001b[32m     17\u001b[39m     eval_frame,\n\u001b[32m     18\u001b[39m     functional_export,\n\u001b[32m     19\u001b[39m     resume_execution,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\aot_compile.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprecompile_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PrecompileContext\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Hooks\n\u001b[32m     19\u001b[39m log = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallbackTrigger\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:59\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m guard_bool\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache_method\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     60\u001b[39m     config,\n\u001b[32m     61\u001b[39m     exc,\n\u001b[32m     62\u001b[39m     graph_break_hints,\n\u001b[32m     63\u001b[39m     logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging,\n\u001b[32m     64\u001b[39m     trace_rules,\n\u001b[32m     65\u001b[39m     variables,\n\u001b[32m     66\u001b[39m )\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     68\u001b[39m     get_indexof,\n\u001b[32m     69\u001b[39m     JUMP_OPNAMES,\n\u001b[32m     70\u001b[39m     livevars_analysis,\n\u001b[32m     71\u001b[39m     propagate_line_nums,\n\u001b[32m     72\u001b[39m )\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     74\u001b[39m     cleaned_instructions,\n\u001b[32m     75\u001b[39m     create_binary_slice,\n\u001b[32m   (...)\u001b[39m\u001b[32m     87\u001b[39m     unique_id,\n\u001b[32m     88\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py:58\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresume_execution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     52\u001b[39m     getfile,\n\u001b[32m     53\u001b[39m     hashable,\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m     unwrap_if_wrapper,\n\u001b[32m     57\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     59\u001b[39m     BuiltinVariable,\n\u001b[32m     60\u001b[39m     FunctionalCallVariable,\n\u001b[32m     61\u001b[39m     FunctorchHigherOrderVariable,\n\u001b[32m     62\u001b[39m     LocalGeneratorFunctionVariable,\n\u001b[32m     63\u001b[39m     LocalGeneratorObjectVariable,\n\u001b[32m     64\u001b[39m     NestedUserFunctionVariable,\n\u001b[32m     65\u001b[39m     PolyfilledFunctionVariable,\n\u001b[32m     66\u001b[39m     ReparametrizeModuleCallVariable,\n\u001b[32m     67\u001b[39m     SkipFunctionVariable,\n\u001b[32m     68\u001b[39m     TorchInGraphFunctionVariable,\n\u001b[32m     69\u001b[39m     UserFunctionVariable,\n\u001b[32m     70\u001b[39m     UserMethodVariable,\n\u001b[32m     71\u001b[39m )\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[32m     75\u001b[39m np: Optional[types.ModuleType] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:19\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThis package implements variable tracking and symbolic execution capabilities for Dynamo,\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mwhich are essential for converting Python code into FX graphs. It provides a comprehensive\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03mallows Dynamo to accurately trace and optimize Python code while preserving its semantics.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuiltin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BuiltinVariable\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable, EnumVariable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\variables\\base.py:650\u001b[39m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    647\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(typestr, objs))\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\variables\\builder.py:263\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msdpa\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SDPAParamsVariable\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    256\u001b[39m     NumpyNdarrayVariable,\n\u001b[32m    257\u001b[39m     supported_const_comparison_op_values,\n\u001b[32m   (...)\u001b[39m\u001b[32m    261\u001b[39m     UnspecializedPythonVariable,\n\u001b[32m    262\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    264\u001b[39m     DispatchKeySetVariable,\n\u001b[32m    265\u001b[39m     FuncTorchInterpreterVariable,\n\u001b[32m    266\u001b[39m     TorchCtxManagerClassVariable,\n\u001b[32m    267\u001b[39m     TorchInGraphFunctionVariable,\n\u001b[32m    268\u001b[39m )\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtorch_function\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    270\u001b[39m     TensorWithTFOverrideVariable,\n\u001b[32m    271\u001b[39m     torch_function_mode_stack_state_mgr,\n\u001b[32m    272\u001b[39m     TorchFunctionModeVariable,\n\u001b[32m    273\u001b[39m )\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01muser_defined\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    275\u001b[39m     FrozenDataClassVariable,\n\u001b[32m    276\u001b[39m     IntWrapperVariable,\n\u001b[32m   (...)\u001b[39m\u001b[32m    286\u001b[39m     UserDefinedTupleVariable,\n\u001b[32m    287\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\variables\\torch.py:156\u001b[39m\n\u001b[32m    140\u001b[39m REWRITE_OPS_TO_TENSOR_SIZE_METHOD = \u001b[38;5;28mdict\u001b[39m.fromkeys(\n\u001b[32m    141\u001b[39m     [\n\u001b[32m    142\u001b[39m         torch._shape_as_tensor,\n\u001b[32m    143\u001b[39m     ]\n\u001b[32m    144\u001b[39m )\n\u001b[32m    146\u001b[39m constant_fold_functions_need_guards = [\n\u001b[32m    147\u001b[39m     torch.accelerator.current_device_index,\n\u001b[32m    148\u001b[39m     torch.cuda.current_device,\n\u001b[32m   (...)\u001b[39m\u001b[32m    151\u001b[39m     torch.xpu.is_initialized,\n\u001b[32m    152\u001b[39m ]\n\u001b[32m    154\u001b[39m constant_fold_functions = [\n\u001b[32m    155\u001b[39m     torch._assert,\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_utils\u001b[49m._get_device_index,\n\u001b[32m    157\u001b[39m     torch._C._get_cublas_allow_tf32,\n\u001b[32m    158\u001b[39m     torch._C._is_any_autocast_enabled,\n\u001b[32m    159\u001b[39m     torch.accelerator.is_available,\n\u001b[32m    160\u001b[39m     torch.cuda.get_device_properties,\n\u001b[32m    161\u001b[39m     torch.cuda.is_available,\n\u001b[32m    162\u001b[39m     torch.distributed.is_available,\n\u001b[32m    163\u001b[39m     torch.get_autocast_dtype,\n\u001b[32m    164\u001b[39m     torch.get_autocast_gpu_dtype,\n\u001b[32m    165\u001b[39m     torch.get_default_dtype,\n\u001b[32m    166\u001b[39m     torch.is_autocast_cache_enabled,\n\u001b[32m    167\u001b[39m     torch.is_autocast_cpu_enabled,\n\u001b[32m    168\u001b[39m     torch.is_autocast_enabled,\n\u001b[32m    169\u001b[39m     torch.is_complex,\n\u001b[32m    170\u001b[39m     torch.is_floating_point,\n\u001b[32m    171\u001b[39m     torch.nn.functional._Reduction.get_enum,  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    172\u001b[39m     torch.promote_types,\n\u001b[32m    173\u001b[39m     torch._C._get_privateuse1_backend_name,\n\u001b[32m    174\u001b[39m     torch.autograd._is_checkpoint_valid,\n\u001b[32m    175\u001b[39m     torch.xpu.get_device_properties,\n\u001b[32m    176\u001b[39m     torch.xpu.is_available,\n\u001b[32m    177\u001b[39m ] + constant_fold_functions_need_guards\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.distributed.is_available():\n\u001b[32m    179\u001b[39m     constant_fold_functions.extend(\n\u001b[32m    180\u001b[39m         [\n\u001b[32m    181\u001b[39m             torch.distributed.is_initialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    184\u001b[39m         ]\n\u001b[32m    185\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\__init__.py:2757\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   2754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _lazy_modules:\n\u001b[32m   2755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[34m__name__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2757\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch' has no attribute '_utils'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(),lr = 1e-3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ef84f4c-37ff-4f27-98a9-0abfb9c47504",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb09e9f4-661a-42f6-9d68-48897408b79b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
