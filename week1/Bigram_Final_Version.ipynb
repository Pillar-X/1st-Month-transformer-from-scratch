{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cec333c3-08a1-4b17-9ecc-80c9493cb29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt','r',encoding = 'utf-8') as F:\n",
    "    text = F.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11076190-3c14-4ced-8f47-1316bef9de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = sorted(list(set(text)))\n",
    "vocab_size = len(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31495d2f-139f-4d94-820b-8e5631988fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {i:c for i,c in enumerate(vocabs)}\n",
    "stoi = {c:i for i,c in enumerate(vocabs)}\n",
    "encoding = lambda s : [stoi[c] for c in s]\n",
    "decoding = lambda l : [itos[i] for i in l]\n",
    "#制定单个字符的index<->char表\n",
    "#以及encoding:传入string->list[idx] 和 decoding: list[idx] -> string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b20d508-13ea-4703-be95-7019faac3487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "n = int(len(text)*0.9)\n",
    "train_data = text[:n]\n",
    "vel_data = text[n:]\n",
    "train_data = encoding(train_data)\n",
    "train_data = torch.tensor(train_data,dtype = torch.long)\n",
    "vel_data = torch.tensor(encoding(vel_data),dtype = torch.long)\n",
    "#将train_data,vel_data转为tensor类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "512ca584-ca24-4756-8be4-0e4956c79c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "block_size = 8\n",
    "torch.manual_seed(1337)\n",
    "def train_pair(trail):\n",
    "    if trail == 'train': data = train_data\n",
    "    else: data = vel_data\n",
    "    \n",
    "    select = torch.randint(len(data)-block_size,(block_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in select] )\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in select])        #?\n",
    "    return x,y\n",
    "#x,y is (B,T)\n",
    "#调用的时候随机生成idx 和 target 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67a28427-30d9-40ec-aad5-d95712e82415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class Bigram_Module(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__() #继承父类，这样才能保证optimizer等能正确找到参数，进行更新（已经在父类中包装好了）\n",
    "        self.embedding_table = nn.Embedding(vocab_size,vocab_size) # 模块如Embedding,Linear等需要在构造方法中写好\n",
    "        #这里Embedding只是相当于声明了一个vocab_size -> vocab_size的table\n",
    "        \n",
    "    def forward(self,idx,target = None):# 目的：返回logits和计算loss\n",
    "        logits = self.embedding_table(idx)\n",
    "        B,T,C = logits.shape\n",
    "        if target is None: # 不能用target==None 来判定，否则会返回tensor而非boelean\n",
    "            loss = None\n",
    "        else:\n",
    "            \n",
    "            logits = logits.view(B*T,C)\n",
    "            target = target.view(B*T)\n",
    "            loss = F.cross_entropy(logits,target) \n",
    "            #交叉熵的传入格式：idx: (N,C) , target: (N,) 此方法会自动根据C代表的logits以及target给出的正确值，计算到答案\n",
    "\n",
    "        return logits,loss\n",
    "\n",
    "    def generate(self,idx,max_num):\n",
    "        for _ in range(max_num):\n",
    "            logits = self.embedding_table(idx)\n",
    "            logits = logits[:,-1,:]                 #前面的概率用不着\n",
    "            probs = F.softmax(logits,dim = 1)\n",
    "            idx_new = torch.multinomial(probs,1)\n",
    "            idx = torch.cat((idx,idx_new),dim = 1)\n",
    "        return idx    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ca26566-66b4-45a4-b30e-4af4dc221e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Bigram_Module(vocab_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "40d27aa1-fc5f-4c87-960d-d53bb1e7ce72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4952, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(),1e-1)\n",
    "\n",
    "for _ in range(100):\n",
    "    x,y = train_pair('train')\n",
    "    logits,loss = m.forward(x,y)\n",
    "    optimizer.zero_grad(set_to_none=True) #清空上一轮梯度值\n",
    "    loss.backward() #内部自动计算梯度\n",
    "    optimizer.step() #根据步长和梯度进行矩阵更新\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c17e6375-81a3-4491-91ab-109756b55916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I were that nd bll fryot hicksane sput\n",
      "IOUSTofallir f ncotece ard sthene, thes o t pe; d w tl ily n y, o,\n",
      "MIs and hre ve teles se.\n",
      "\n",
      "Whate d.\n",
      "\n",
      "\n",
      "Whepimpis\n",
      "\n",
      "Hentt ande\n",
      "ARIndatha whacongrt s eate ns oure found ds de r s de trilarinemee fr h ICE:\n",
      "\n",
      "Whal ourtil y us angr s lo o'licof uplicof hed co my sesp ty iscad ort,\n",
      "BELARimat,\n",
      "N thids t RI h,\n",
      "ABundato ld s ane\n",
      "\n",
      "Wis gus he; laray mencenearsend anthem\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1),dtype = torch.long)\n",
    "max_num = 400\n",
    "print(''.join(decoding(m.generate(idx,max_num)[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171a25c-430b-4302-a8f4-f7c079900fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
